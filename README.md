# Data Engineering Masterclass

<p align="center"> <img src="https://pbs.twimg.com/profile_images/1341352412540530688/EJfGb11W_400x400.jpg"> </img></p>

Bu Repo [Data Engineering Masterclass (DEMCâ€“201)](https://datamasterclass.zeministanbul.ist) eÄŸitiminde verilen derslerin iÃ§eriklerini ve notlarÄ±nÄ± iÃ§ermektedir.

**TanÄ±m:** Data Engineering Masterclass (DEMCâ€“201) veri odaklÄ± teknolojik Ã¼rÃ¼n geliÅŸtirme ekiplerinin veri mÃ¼hendisliÄŸi ihtiyaÃ§larÄ± gÃ¶zetilerek hazÄ±rlanmÄ±ÅŸ bir uzmanlÄ±k sÄ±nÄ±fÄ±dÄ±r. Bu uzmanlÄ±k sÄ±nÄ±fÄ±, data engineering alanÄ±nda uzun yÄ±llar Ã§alÄ±ÅŸmÄ±ÅŸ, deneyim sahibi yazÄ±lÄ±m geliÅŸtiriciler, veri mÃ¼hendisleri, veri bilimcileri ve sistem mÃ¼hendisleri tarafÄ±ndan hazÄ±rlanmÄ±ÅŸtÄ±r.

## Contributors

- Mert Ã‡obanov
- Ã‡aÄŸrÄ± KÃ¶z

## Ä°Ã§indekiler

| Topic           | Day                                                        |
| --------------- | ---------------------------------------------------------- |
| Data Collection | [Day 1](https://github.com/cobanov/dataeng-bootcamp#day-1) |
| Data Collection | [Day 2](https://github.com/cobanov/dataeng-bootcamp#day-2) |
| Data Cleaning   | TBD                                                        |

| Files              | Link                                                                                       |
| ------------------ | ------------------------------------------------------------------------------------------ |
| Webscraping Script | [.py](https://github.com/cobanov/dataeng-bootcamp/blob/main/homeworks/extractFromVatan.py) |
| AWK Cheatsheet     | [PDF](https://github.com/cobanov/dataeng-bootcamp/blob/main/additional/AWK.pdf)            |



## **ModÃ¼l-1: Data Collection**

**Ä°Ã§erik:**Â API'lar, loglama, sensory data, web scraping.

**Anahtar sÃ¶zcÃ¼kler:**Â JSON, XML, HTTP, HTML, DOM, grep, RegExp.

**AraÃ§lar:**Â Postman, log4j, python-logging, BeautifulSoup, Jsoup, Selenium

## Day 1

## Data Toplama

Information retrieval, web-scraping, alÄ±nan API datalarÄ± bunlara Ã¶rnektir.

---

## **API**

Ä°ki sistemin arasÄ±nda nasÄ±l konusacaÄŸÄ±nÄ± belirleyen bir yapÄ±dÄ±r. Belirli spesifik tipte akÄ±ÅŸ ve veri sunar. Belirli bir rate iÃ§erisinde olmaktadÄ±r. Belirli sorgulara karÅŸÄ± belirli bir data parÃ§asÄ± geÃ§mektedir, tÃ¼m sistemin veri akÄ±ÅŸÄ±nÄ± saÄŸlamak iÃ§in deÄŸildir.

FarklÄ± formatlarda dÃ¶nÃ¼ÅŸÃ¼ olabilir. **.xml** veya **json** olabilir. JSON oldukÃ§a popÃ¼ler, ÅŸu an genel akÄ±m json Ã¼zerinden Ã§alÄ±ÅŸÄ±yor.

SensÃ¶rlere ufak bilgisayarlar denilebilir, genellikle amaca yÃ¶nelik sadece gÃ¶revini yapan pil Ã¶mrÃ¼ yÃ¼ksek olan mini cihazlardÄ±r. Ãœzerindeki datayÄ± merkeze alÄ±narak kullanÄ±lÄ±r. _AslÄ±nda **edgedeki** cihazlardan bahsediliyor._

---

## **Web Scraping**

GÃ¶rece API'ye gÃ¶re verinin elde edilmesi daha zordur. Veri genellikle daÄŸÄ±nÄ±k biÃ§imde web'de bulunur, veri toplama prosesi kullanÄ±cÄ±nÄ±n bu rotalarÄ± tanÄ±mlayarak gerÃ§ekleÅŸtirmesiyle saÄŸlanÄ±r. DezavantajÄ± ise belirli bir protokolun olmamasÄ±, **_challenging but fun!_**

DeÄŸiÅŸikliklerde call denilen bir sistem kullanÄ±labilir. Ä°ki taraf iÃ§in yÃ¼klÃ¼ bir sistem olduÄŸundan dolayÄ± istenilen bir yÃ¶ntem deÄŸildir. Bir websitesi iÃ§in yazÄ±lan scraping scriptleri her gÃ¼n deÄŸiÅŸmez bu yÃ¼zden bÃ¼yÃ¼k bir problem yaratmayacaktÄ±r. Subscribe yÃ¶nteminde webhook gibi yÃ¶ntemler kullanÄ±labilir fakat karÅŸÄ± tarafÄ±n da sizi tanÄ±yor olmasÄ± gerek.

---

## Loglama

Genellikle problemler belirli bir zaman diliminden itibaren veya geÃ§miÅŸten gelir. AnlÄ±k sorunlarÄ± ve sistemin ne yaptÄ±ÄŸÄ±nÄ± en ince detayÄ±n kadar gÃ¶rmek iÃ§in **loglama** kullanÄ±lÄ±r.

**Pro Tip:** Her satÄ±rÄ±n loglanmasÄ±nÄ±n anlamÄ± yoktur. Bu yÃ¶ntem oldukÃ§a dikkat daÄŸÄ±tÄ±cÄ± ve kullanÄ±ÅŸsÄ±z olabilir. Bunun iÃ§in loglamanÄ±n seviyeleri vardÄ±r.

### LoglamanÄ±n seviyeleri

Low level, critical, warning, info gibi seviyeler vardÄ±r.

- **Debug:** SorunlarÄ±n teÅŸhisi iÃ§in debugging gibi dÃ¼ÅŸÃ¼nebiliriz. AyrÄ±ntÄ±lÄ± bilgilere ihtiyacÄ±mÄ±z vardÄ±r.
- **Info:** Beklenen Ã§Ä±ktÄ±larÄ±mÄ±zdÄ±r.
- **Warning:** YazÄ±lÄ±m hala Ã§alÄ±ÅŸÄ±yordur ama uyarÄ± Ã§anlarÄ± Ã§almaktadÄ±r.
- **Error:** YazÄ±lÄ±m ciddi bir sorunla karÅŸÄ±laÅŸtÄ± ve gÃ¶revini yerine getiremedi.
- **Critical**: ProgramÄ±n iÅŸlevini yerine getiremeyecek bir sorunla karÅŸÄ±laÅŸmasÄ±dÄ±r.

**Pro Tip:** _grep_ komutuyla dosyalarÄ±n iÃ§erisindeki belirli kelimeyi arar. _(e.g. 2 ÅŸubat tarihinde bir problem oldu ve onun bulunmasÄ± iÃ§in kullanÄ±labilir.)_

### Loglama yaparken:

- **Timestamp:** Tarih, zaman damgasÄ± bulunmasÄ± ve ne zaman olduÄŸuna dair bilgi vermesi aÃ§Ä±sÄ±ndan Ã¶nemlidir.
- **Logging Level:** HatanÄ±n derecesi, nedeni veya olayÄ±n ne olduÄŸuna dair seviyenin belirtilmesi gerekmektedir.
- **API Bilgisi:** Sensor ID, hangi fonksiyon, genel bilgiler iÃ§ermelidir.
- **Logun iÃ§eriÄŸi:** value, logun iÃ§eriÄŸi json, plain text, xml olabilir.

LoglarÄ± tek bÃ¼yÃ¼k bir dosyada depolamak giderek bÃ¼yÃ¼yen bir dosya olacaÄŸÄ±ndan dolayÄ± mantÄ±klÄ± deÄŸildir. Databasede tablo olarak saklanabilir bÃ¶yle bir durumda select sÃ¼resi giderek uzayacaktÄ±r. Sistemi optimize edebilmek iÃ§in aktif olanlar veya olmayanlar yahut arÅŸivlenmiÅŸ gibi farklÄ± parÃ§alara bÃ¶lmek zaman aÃ§Ä±sÄ±ndan yararlÄ± olacaktÄ±r.

Bu gibi bÃ¼yÃ¼k Ã§aplÄ± verilerde hÄ±zlÄ± iÅŸlemler yapabilmek iÃ§in **Hadoop** gibi Ã¶zelleÅŸmiÅŸ sistemler bulunmaktadÄ±r. Temelde depolanan ve gÃ¼ncel olarak kullanÄ±lan iki parÃ§aya bÃ¶lmek mantÄ±klÄ± olacaktÄ±r.

---

### Keywords:

- **POSTMAN:** APIâ€™larÄ± paylaÅŸmak, test etmek, dokÃ¼mante etmek, monitÃ¶r etmek iÃ§in kullanÄ±lÄ±r. En Ã¶ne Ã§Ä±kan Ã¶zelliÄŸi tÃ¼m bunlar iÃ§in Ã§ok kullanÄ±ÅŸlÄ± bir arayÃ¼z sunmasÄ±dÄ±r.
- **Log4j:** Java uygulamalarÄ±nda kullanÄ±lacak loglama kÃ¼tÃ¼phanesidir.
- **python-logging:** Log4j'in python versiyonu
- **BeautifulSoup:** BeautifulSoup, HTML veya XML dosyalarÄ±nÄ± iÅŸlemek iÃ§in oluÅŸturulmuÅŸ bir kÃ¼tÃ¼phanedir.
- **Jsoup:** BS4'un java versiyonu
- **Selenium:** Selenium, bilgisayarÄ±nÄ±za yÃ¼kleyeceÄŸiniz bir driver yardÄ±mÄ± ile ekrana chrome, firefox gibi bir tarayÄ±cÄ± aÃ§arak, gerÃ§ek bir insan gibi istediÄŸiniz tÃ¼m iÅŸlemleri programlama dili yardÄ±mÄ±yla Ã§alÄ±ÅŸtÄ±rmanÄ±zÄ± saÄŸlayan bir araÃ§tÄ±r.

### End of the first day!

## Day 2

## HTTP

â€œhttpâ€, bilginin sunucudan kullanÄ±cÄ±ya nasÄ±l ve ne ÅŸekilde aktarÄ±lacaÄŸÄ±nÄ± gÃ¶steren protokoldÃ¼r. Ä°nternet aÄŸÄ±nda sunucular ve kullanÄ±cÄ±lar arasÄ±nda nasÄ±l bir veri alÄ±ÅŸveriÅŸi olacaÄŸÄ± hakkÄ±nda kurallar vardÄ±r. Bu dÃ¼zeni saÄŸlayan protokol de HTTPâ€™dir.internet sitesine girmek iÃ§in adres Ã§ubuÄŸuna sitenin adresini yazdÄ±ÄŸÄ±nÄ±z vakit HTTP ile sunucuya bir istek gÃ¶nderilir ve sunucu bu isteÄŸe cevap verdiÄŸi vakit internet sitesinin verileri size gelir.

## ğŸ¢ Restful Mimarisi

RESTful servisler veri iletiminde farklÄ± HTTP metotlarÄ±nÄ± kullanmaktadÄ±r. YapÄ±lan HTTP requestâ€™i iÃ§in Ã§aÄŸrÄ±lan URL ile beraber HTTP method bilgisi bahsi geÃ§en 4 metottan biri olarak seÃ§ilir ve sunucu yapÄ±lan talebin kayÄ±t Ã¼zerine nasÄ±l etki edeceÄŸini buna gÃ¶re belirler.

**GET:** Veri listeleme - veri gÃ¶rÃ¼ntÃ¼lemek iÃ§in kullanÄ±lÄ±r.

**POST:** Veri eklemek iÃ§in kullanÄ±lÄ±r.

### DiÄŸer Metodlar

- **PUT:** Veriyi GÃ¼ncelleme isteÄŸi olarak kullanÄ±lÄ±r.
- **PATCH:** Verinin sadece bir parÃ§asÄ±nÄ± gÃ¼ncellemek iÃ§in kullanÄ±lÄ±r. Ã–rneÄŸin birÂ issue'nun durumunun aktiften Ã§Ã¶zÃ¼ldÃ¼ haline getirilmesi.
- **DELETE:** Veriyi silmek iÃ§in kullanÄ±lÄ±r.
- **OPTIONS:** Bir Â api urline Options isteÄŸi yapÄ±ldÄ±ÄŸÄ±nda o url in hangi istekleri kabul ettiÄŸi bilgisi verilir.

[httpbin.org](http://httpbin.org) sitesinden bu denemeler yapÄ±labilir

## HTTP Status kodlarÄ±

Kodlara linkten ulaÅŸÄ±labilir. [https://www.argenova.com.tr/http-durum-ve-hata-kodlari](https://www.argenova.com.tr/http-durum-ve-hata-kodlari)

### En sÄ±k karÅŸÄ±laÅŸÄ±lan hata kodlarÄ±

- **HTTP 200 (OK):** yanÄ±tÄ±n baÅŸarÄ±lÄ± olduÄŸunu gÃ¶sterir. Yani, istemci ile sunucu arasÄ±ndaki iletiÅŸim herhangi bir hata olmadan sorunsuz bir ÅŸekilde yÃ¼rÃ¼tÃ¼lmÃ¼ÅŸtÃ¼r.
- **HTTP 404 (Not Found):** istenen kaynaÄŸÄ±n sunucu tarafÄ±ndan bulunamayacaÄŸÄ± anlamÄ±na gelir. Bu, geÃ§ici bir aksaklÄ±ktan kaynaklanÄ±yor olabilir ve gelecekte baÅŸka bir istekte bulunulursa kaynak kullanÄ±labilir olabilir. Ã‡oÄŸunlukla, 404'e gÃ¶tÃ¼ren baÄŸlantÄ±lara genellikle bozuk baÄŸlantÄ±lar denir.
- **HTTP 502 (Bad Gateway):** sunucunun proxy olarak hareket ederken istekte bulunurken sunucudan geÃ§ersiz bir yanÄ±t aldÄ±ÄŸÄ±nÄ± gÃ¶sterir.

## ğŸ¥Œ CURL

Ã‡oÄŸu Unix bazlÄ± sistemde mevcut olan bir komuttur ve â€œClient URLâ€nin kÄ±saltÄ±lmÄ±ÅŸÄ±dÄ±r. Curl komutlarÄ± URLâ€™lerin baÄŸlanabilirliÄŸini kontrol etmek ve veri transferi iÃ§in harika bir araÃ§ olarak kullanÄ±lmak iÃ§in Ã¼retilmiÅŸtir.

### **Basit Curl Command SÃ¶zdizimi**

Hadi Curl komutlarÄ±nÄ± nasÄ±l kullanacaÄŸÄ±mÄ±zÄ± Ã¶ÄŸrenelim. Curlâ€™Ã¼n basit sÃ¶zdizimi bÃ¶yledir:

```
curl [OPTIONS] [URL]
```

Curlâ€™Ã¼n en basit kullanÄ±mÄ± bir sayfanÄ±n iÃ§eriklerini gÃ¶stermektir. AÅŸaÄŸÄ±daki Ã¶rnek testalanadi.comâ€™un ana sayfasÄ±nÄ±n iÃ§eriklerini gÃ¶sterecektir:

```
curl testalanadi.com
```

### Derste kullanÄ±lan Ã¶rnekler

```jsx
curl -x GET "http://httpbin.org/get" -H "accept: application/json"
```

ipify.org

[https://api.ipify.org?format=json&param=2](https://api.ipify.org/?format=json&param=2)

### URL iÃ§erisindeki Ã¶zel karakterler

- **"?":** "sorgu parametreleri" olarak adlandÄ±rÄ±lÄ±r. Sunucu, bu ek bilgilere dinamik olarak cevap verebilir ve gÃ¶receÄŸiniz sayfayÄ± bu parametrelere gÃ¶re oluÅŸturabilir. Bu, sayfadaki bir alana otomatik olarak yazÄ±lmÄ±ÅŸ bir bilgi veya bir arama motorundaki arama sorgunuz olabilir.
- **"%":** "Escaping" olarak adlandÄ±rÄ±lan bu iÅŸlem, URL'deki boÅŸluk karakterinin soruna yol aÃ§mamasÄ± iÃ§in alternatif bir biÃ§ime dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesidir. Ã–rneÄŸin + yazdÄ±ÄŸÄ±nÄ±zda bu karakter, %3F ile deÄŸiÅŸtirilir.
- **"=":** anahtar-deÄŸer Ã§iftlerini temsil eder. Anahtar-deÄŸer Ã§iftine bir Ã¶rnek, sayfa=4 olabilir. Burada "sayfa" anahtar, "4" ise deÄŸerdir.

## ğŸš€ GREP

Elimizdeki loglarda buradan terminal ekranÄ±nda hÄ±zlÄ±ca sorgularÄ±mÄ±z getirebiliriz. LoglarÄ±n gÃ¼zel ÅŸekilde tutulmasÄ± iÅŸimizi kolaylaÅŸtÄ±rÄ±yor. Pipe ile Ã§ok daha etkin kullanÄ±m yÃ¶ntemleri mevcut.

grep "42.236.10.125" \* â€”color | wc -lw

### ğŸ“š Ders Ã–rnekleri:

grep "GET" \* â€”color

grep "42.236.10.125" \* â€”color | wc -lw

grep "mozilla" \* â€”color

## ğŸŒ² DOM

HTML iÃ§in kullanÄ±lan dokÃ¼man nesne modelidir. HTML Elementlerini objeler olarak, HTML elementlerinin tÃ¼m Ã¶zelliklerini, HTML elementlerine eriÅŸmek iÃ§in metotlarÄ±, tÃ¼m HTML elementleri iÃ§in olaylarÄ± tanÄ±mlar. DiÄŸer bir deyiÅŸle HTML DOM yeni elementler eklemek, elementleri deÄŸiÅŸtirmek veya silmek iÃ§in kullanÄ±lÄ±r.

![https://biltektasarim.com/biltek3/dosyalar/kcfinder/images/transparent_dom.png](https://biltektasarim.com/biltek3/dosyalar/kcfinder/images/transparent_dom.png)

```html
<html>
  <head>
    <title></title>
    <style></style>
  </head>
  <body>
    <div>
      <p>Cobanov</p>
    </div>
  </body>
</html>
```

## ğŸ Python Web Scraping

### Logging

**Kaynak**: [https://medium.com/@umut.boz/python-logging-a8fdd36fee7](https://medium.com/@umut.boz/python-logging-a8fdd36fee7)

Loglama, bir sistemdeki hareketliliÄŸi kaydetmek iÃ§in kullanÄ±lan yapÄ±dÄ±r. Python standart kÃ¼tÃ¼phanesi iÃ§inde loglama iÃ§in Ã§ok gÃ¼Ã§lÃ¼ bir kÃ¼tÃ¼phane barÄ±ndÄ±rÄ±r. Bu kÃ¼tÃ¼phane ile geliÅŸtirdiÄŸimiz programlarda hata ayÄ±klamak aynÄ± zamanda ifadeleri yazdÄ±rmak iÃ§in loglama kullanabiliriz.

### Requests

**Kaynak**: [https://medium.com/python/python-requests-modÃ¼lÃ¼-4af79ebdb8c8](https://medium.com/python/python-requests-mod%C3%BCl%C3%BC-4af79ebdb8c8)

Python, standart modÃ¼llerinin yanÄ±nda harici yÃ¼zlerce kullanÄ±ÅŸlÄ± modÃ¼l ile birlikte Ã§ok gÃ¼Ã§lÃ¼ bir dil. Bu gÃ¼cÃ¼ veren harika modÃ¼ller var bunlardan biri deÂ **Requests modÃ¼lÃ¼.**

Bu modÃ¼l ile web Ã¼zerindeki isteklerinizi yÃ¶neteceksiniz. Mesela bu modÃ¼l ile API entpointlerine PUT, DELETE, POST gibi istekler atabilirsiniz.

### BeautifulSoup4

**Kaynak**: [https://medium.com/@nuriyavuz2.71/python-beautifulsoup-modÃ¼lÃ¼-689ef499ee16](https://medium.com/@nuriyavuz2.71/python-beautifulsoup-mod%C3%BCl%C3%BC-689ef499ee16)

BeautifulSoup, HTML veya XML dosyalarÄ±nÄ± iÅŸlemek iÃ§in oluÅŸturulmuÅŸ gÃ¼Ã§lÃ¼ ve hÄ±zlÄ± bir kÃ¼tÃ¼phanedir.

Bu modÃ¼l ile bir kaynak iÃ§erisindeki HTML kodlarÄ±nÄ± parse edip,botlar yazabiliriz.

### Selenium

**Kaynak**: [https://www.sinanerdinc.com/python-selenium-modulu-kullanimi-1](https://www.sinanerdinc.com/python-selenium-modulu-kullanimi-1)

Selenium, bilgisayarÄ±nÄ±za yÃ¼kleyeceÄŸiniz bir driver yardÄ±mÄ± ile ekrana chrome, firefox gibi bir tarayÄ±cÄ± aÃ§arak, gerÃ§ek bir insan gibi istediÄŸiniz tÃ¼m iÅŸlemleri programlama dili yardÄ±mÄ±yla Ã§alÄ±ÅŸtÄ±rmanÄ±zÄ± saÄŸlayan bir araÃ§tÄ±r.

**Homework:** Vatan bilgisayardaki Ã¼rÃ¼nlerin gÃ¶rsellerin veya isimleri ile Ã¼cretlerini scrap edebilirsin.

**Ã–dev Linki:** [https://github.com/cobanov/dataeng-bootcamp/blob/main/homeworks/scraping_homework.py](https://github.com/cobanov/dataeng-bootcamp/blob/main/homeworks/scraping_homework.py)

### ğŸ”— **GISTLER:**

- **BS4**: [https://gist.github.com/sirin/695abacaa207ad7af20f18c946d19858](https://gist.github.com/sirin/695abacaa207ad7af20f18c946d19858)
- **Selenium**: [https://gist.github.com/sirin/0e1491163b8f485a476e0991ad228b86](https://gist.github.com/sirin/0e1491163b8f485a476e0991ad228b86)

### End of the second day!
